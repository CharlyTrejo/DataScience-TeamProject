{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos nuestras credenciales de AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_session = boto3.Session(\n",
    "    aws_access_key_id = \"access_key\",\n",
    "    aws_secret_access_key = \"secret_key\",\n",
    "    region_name = \"region_name\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id= \"access_key\",\n",
    "    aws_secret_access_key= \"secret_key\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos bucket donde irán los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.create_bucket(Bucket=\"Bucket Name\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que estén cargados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.s3.list_objects(\"s3://Bucket Name\", boto3_session=my_session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicamos el proceso de **ETL** a cada dataset de nuestro bucket de S3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabla Gini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos nuestro dataset\n",
    "df_gini = wr.s3.read_csv(path=\"s3://data-fm-05/raw_data/gini.csv\", boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_gini.rename(columns={'Entity':'pais','Code':'codigo_pais', 'Year':'anio', 'Gini coefficient': 'valor'}, inplace=True)\n",
    "df_gini.fillna(0, inplace= True)\n",
    "\n",
    "#Enviamos el dataset limpio a otro bucket\n",
    "wr.s3.to_csv(df=df_gini,path=\"s3://data-fm-05/clean_data/gini.csv\", boto3_session=my_session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabla PIB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos nuestro dataset\n",
    "df_PIB = wr.s3.read_csv(path=\"s3://data-fm-05/raw_data/Pib.csv\", boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_PIB.drop(['Indicator Name', 'Indicator Code', 'Unnamed: 66'], axis=1, inplace= True)\n",
    "df_PIB.drop(columns=df_PIB.columns[2:32],axis=1,inplace= True)\n",
    "df_PIB.drop([1,3], axis=0, inplace=True)\n",
    "df_PIB.fillna(0, inplace= True)\n",
    "df_PIB.rename(columns={'Country Name':'pais','Country Code':'codigo_pais'}, inplace=True)\n",
    "\n",
    "#Enviamos el dataset limpio a otro bucket\n",
    "wr.s3.to_csv(df=df_PIB, path=\"s3://data-fm-05/clean_data/Pib.csv\", boto3_session=my_session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabla Empleo por sector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos nuestro dataset\n",
    "df_empleo_sector = wr.s3.read_csv(path='s3://data-fm-05/raw_data/Employment_for_sector.csv', sep= ';', boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_empleo_sector.drop(['Series Code', '1990 [YR1990]'], axis=1, inplace= True)\n",
    "df_empleo_sector.drop(df_empleo_sector.index[1596:1601], axis=0, inplace=True)\n",
    "df_empleo_sector.rename(columns={'Series Name':'sector',\n",
    "                              'Country Name':'pais', \n",
    "                              'Country Code':'codigo_pais',\n",
    "                              '1990 [YR1990]':'1990', '2000 [YR2000]':'2000', '2012 [YR2012]':'2012',\n",
    "                              '2013 [YR2013]':'2013', '2014 [YR2014]':'2014', '2015 [YR2015]':'2015',\n",
    "                              '2016 [YR2016]':'2016', '2017 [YR2017]':'2017', '2018 [YR2018]':'2018',\n",
    "                              '2019 [YR2019]':'2019', '2020 [YR2020]':'2020', '2021 [YR2021]':'2021'}, inplace=True)\n",
    "df_empleo_sector.replace({\"..\": 0}, inplace= True)\n",
    "\n",
    "#Enviamos el dataset limpio a otro bucket\n",
    "wr.s3.to_csv(df=df_empleo_sector, path='s3://data-fm-05/clean_data/Employment_for_sector.csv', boto3_session=my_session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabla Industria migracion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos nuestro dataset\n",
    "df_industria = wr.s3.read_csv(path='s3://data-fm-05/raw_data/industry_migration_public.csv', boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_industria.drop(['wb_income', 'wb_region', 'isic_section_index','industry_id'], axis=1, inplace=True )\n",
    "df_industria.drop(columns=df_industria.columns[9:26],axis=1,inplace= True)\n",
    "df_industria.rename(columns={'country_code ':'codigo_pais','country_name ':'pais',\n",
    "                          'isic_section_name':'sector', 'industry_name':'industria',\n",
    "                          'net_per_10K_2015': '2015', 'net_per_10K_2016': '2016', 'net_per_10K_2017': '2017',\n",
    "                          'net_per_10K_2018': '2018', 'net_per_10K_2019': '2019'}, inplace=True)\n",
    "\n",
    "#Enviamos el dataset limpio a otro bucket\n",
    "wr.s3.to_csv(df=df_industria, path='s3://data-fm-05/clean_data/industry_migration_public.csv', boto3_session=my_session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabla de habilidades migration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos nuestro dataset\n",
    "df_habilidades = wr.s3.read_csv(path='s3://data-fm-05/raw_data/skill_migration_public.csv', boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_habilidades.drop(['wb_income', 'wb_region', 'skill_group_id'], axis=1, inplace=True )\n",
    "df_habilidades.drop(columns=df_habilidades.columns[9:26],axis=1,inplace= True)\n",
    "df_habilidades.rename(columns={'country_code ':'codigo_pais','country_name ':'pais',\n",
    "                          'skill_group_category':'categoria', 'skill_group_name':'habilidad',\n",
    "                          'net_per_10K_2015': '2015', 'net_per_10K_2016': '2016', 'net_per_10K_2017': '2017',\n",
    "                          'net_per_10K_2018': '2018', 'net_per_10K_2019': '2019'}, inplace=True)\n",
    "df_habilidades= df_habilidades.drop_duplicates()\n",
    "\n",
    "#Enviamos el dataset limpio a otro bucket\n",
    "wr.s3.to_csv(df=df_habilidades, path='s3://data-fm-05/clean_data/skill_migration_public.csv', boto3_session=my_session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabla de empleo, desempleo y participacion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos nuestro dataset\n",
    "df_Porcentaje_empleo_desempleo_participacion = wr.s3.read_csv(path=\"s3://data-fm-05/raw_data/Employment_unemployment_and_participation.csv\", boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_Porcentaje_empleo_desempleo_participacion.drop(['BIRTH', 'GENDER', 'RATE', 'YEAR', 'Flag Codes', 'Flags'], axis=1, inplace= True)\n",
    "df_Porcentaje_empleo_desempleo_participacion.drop(columns=df_Porcentaje_empleo_desempleo_participacion.columns[6:12],axis=1,inplace= True)\n",
    "df_Porcentaje_empleo_desempleo_participacion.rename(columns={'COUNTRY':'codigo_pais','Country ':'pais',\n",
    "                          'Place of birth':'lugar_de_nacimiento', 'Gender':'genero',\n",
    "                          'Rate': 'referencia_tasas', 'Year': 'anio', 'Value': 'valor'}, inplace=True)\n",
    "df_Porcentaje_empleo_desempleo_participacion= df_Porcentaje_empleo_desempleo_participacion[(df_Porcentaje_empleo_desempleo_participacion['genero']== 'Total')]\n",
    "df_Porcentaje_empleo_desempleo_participacion.drop(['genero'], axis=1, inplace= True)\n",
    "\n",
    "#Enviamos el dataset limpio a otro bucket\n",
    "wr.s3.to_csv(df=df_Porcentaje_empleo_desempleo_participacion, path='s3://data-fm-05/clean_data/Employment_unemployment_and_participation.csv', boto3_session=my_session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabla de Tasa de participacion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos nuestro dataset\n",
    "df_participacion = wr.s3.read_csv(path='s3://data-fm-05/raw_data/Tasa_participacion_fuerza_trabajo.csv', boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_participacion.drop(['source', 'source.label', 'indicator', 'indicator.label','sex', 'sex.label', 'classif1', 'classif2'], axis=1, inplace= True)\n",
    "df_participacion.drop(columns=df_participacion.columns[6:15],axis=1,inplace= True)\n",
    "df_participacion.rename(columns={'ref_area':'codigo_pais','ref_area.label':'pais',\n",
    "                          'classif1.label':'edad', 'classif2.label':'lugar_de_nacimiento',\n",
    "                          'time': 'anio', 'obs_value': 'valor'}, inplace=True)\n",
    "df_participacion= df_participacion[(df_participacion['edad']== 'Edad (Tramos agregados): Total')]\n",
    "df_participacion.drop(['edad'], axis=1, inplace=True)\n",
    "\n",
    "#Enviamos el dataset limpio a otro bucket\n",
    "wr.s3.to_csv(df=df_participacion, path='s3://data-fm-05/clean_data/Tasa_participacion_fuerza_trabajo.csv', boto3_session=my_session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabla de migracion neta banco mundial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos nuestro dataset\n",
    "df_migracion_neta = wr.s3.read_csv(path='s3://data-fm-05/raw_data/migracion_neta.csv', boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_migracion_neta.drop(['Indicator Name', 'Indicator Code', 'Unnamed: 66'], axis=1, inplace= True)\n",
    "df_migracion_neta.drop(columns=df_migracion_neta.columns[2:32],axis=1,inplace= True)\n",
    "df_migracion_neta.rename(columns={'Country Name':'pais','Country Code':'codigo_pais'}, inplace=True)\n",
    "df_migracion_neta.drop([110], axis=0, inplace=True)\n",
    "\n",
    "#Enviamos el dataset limpio a otro bucket\n",
    "wr.s3.to_csv(df=df_migracion_neta, path='s3://data-fm-05/clean_data/migracion_neta.csv', boto3_session=my_session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fact Empleo Condicion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos nuestro dataset\n",
    "Porcentaje_empleo_desempleo_participacion = wr.s3.read_csv(path=\"s3://data-fm-05/raw_data/Employment_unemployment_and_participation.csv\", boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "Porcentaje_empleo_desempleo_participacion.drop(['BIRTH', 'GENDER', 'RATE', 'YEAR', 'Flag Codes', 'Flags'], axis=1, inplace= True)\n",
    "Porcentaje_empleo_desempleo_participacion.drop(columns=Porcentaje_empleo_desempleo_participacion.columns[6:12],axis=1,inplace= True)\n",
    "Porcentaje_empleo_desempleo_participacion.rename(columns={'COUNTRY':'codigo_pais','Country':'pais',\n",
    "                          'Place of birth':'lugar_de_nacimiento', 'Gender':'genero',\n",
    "                          'Rate': 'referencia_tasas', 'Year': 'anio', 'Value': 'valor'}, inplace=True)\n",
    "Porcentaje_empleo_desempleo_participacion= Porcentaje_empleo_desempleo_participacion[(Porcentaje_empleo_desempleo_participacion['genero']== 'Total')]\n",
    "Porcentaje_empleo_desempleo_participacion.drop(['genero'], axis=1, inplace= True)\n",
    "Porcentaje_empleo_desempleo_participacion_empleados = Porcentaje_empleo_desempleo_participacion[Porcentaje_empleo_desempleo_participacion['referencia_tasas'] == 'Employment rate'].rename(columns={'valor':\"empleados\"}).drop(['referencia_tasas'], axis=1)\n",
    "Porcentaje_empleo_desempleo_participacion_desempleados = Porcentaje_empleo_desempleo_participacion[Porcentaje_empleo_desempleo_participacion['referencia_tasas'] == 'Unemployment rate'].rename(columns={'valor':\"desempleados\"}).drop(['referencia_tasas'], axis=1)\n",
    "Porcentaje_empleo_desempleo_participacion_participacion = Porcentaje_empleo_desempleo_participacion[Porcentaje_empleo_desempleo_participacion['referencia_tasas'] == 'Participation rate'].rename(columns={'valor':\"participacion\"}).drop(['referencia_tasas'], axis=1)\n",
    "\n",
    "\n",
    "merge1 = pd.merge(Porcentaje_empleo_desempleo_participacion_empleados, Porcentaje_empleo_desempleo_participacion_desempleados, on=['codigo_pais','pais','anio','lugar_de_nacimiento'], how='outer')\n",
    "merge2 = pd.merge(merge1, Porcentaje_empleo_desempleo_participacion_participacion, on=['codigo_pais','pais','anio','lugar_de_nacimiento'], how='outer')\n",
    "merge2['lugar_de_nacimiento'].replace(to_replace='Foreign-born', value='extranjero', inplace=True)\n",
    "merge2['lugar_de_nacimiento'].replace(to_replace='Native-born', value='nativo', inplace=True)\n",
    "\n",
    "participacion = wr.s3.read_csv(path='s3://data-fm-05/raw_data/Tasa_participacion_fuerza_trabajo.csv', boto3_session=my_session)\n",
    "participacion.drop(['source', 'source.label', 'indicator', 'indicator.label','sex', 'sex.label', 'classif1', 'classif2'], axis=1, inplace= True)\n",
    "participacion.drop(columns=participacion.columns[6:15],axis=1,inplace= True)\n",
    "participacion.rename(columns={'ref_area':'codigo_pais','ref_area.label':'pais',\n",
    "                          'classif1.label':'edad', 'classif2.label':'lugar_de_nacimiento',\n",
    "                          'time': 'anio', 'obs_value': 'tasa_participacion'}, inplace=True)\n",
    "participacion= participacion[(participacion['edad']== 'Edad (Tramos agregados): Total')]\n",
    "participacion.drop(['edad'], axis=1, inplace=True)\n",
    "participacion['lugar_de_nacimiento'].replace(to_replace='Lugar de nacimiento: Nativo-nacido', value='nativo', inplace=True)\n",
    "participacion['lugar_de_nacimiento'].replace(to_replace='Lugar de nacimiento: Nacido en el extranjero', value='extranjero', inplace=True)\n",
    "\n",
    "fact_empleo_condicion = pd.merge(merge2, participacion, on=['codigo_pais','pais','lugar_de_nacimiento','anio'], how='outer')\n",
    "\n",
    "\n",
    "#Enviamos el dataset limpio a otro bucket\n",
    "wr.s3.to_csv(df=fact_empleo_condicion, path=\"s3://data-fm-05/clean_data/fact_empleo_condicion.csv\", boto3_session=my_session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fact Ind Econonómico**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pib = df_PIB.melt(id_vars=['pais','codigo_pais'], var_name='anio', value_name='PIB')\n",
    "pib['anio'] = pib['anio'].astype('int64')\n",
    "\n",
    "#Cargamos nuestro dataset\n",
    "df_salario_minimo = wr.s3.read_csv(path='s3://data-fm-05/raw_data/salario_minimo_mensual_bruto_anual_dolares.csv', sep=',', header=0, boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_salario_minimo.drop('source', axis=1, inplace=True)\n",
    "df_salario_minimo.drop('source.label', axis=1, inplace=True)\n",
    "df_salario_minimo.drop('indicator', axis=1, inplace=True)\n",
    "df_salario_minimo.drop('indicator.label', axis=1, inplace=True)\n",
    "df_salario_minimo.drop('classif1', axis=1, inplace=True)\n",
    "df_salario_minimo.drop('classif1.label', axis=1, inplace=True)\n",
    "df_salario_minimo.drop('obs_status', axis=1, inplace=True)\n",
    "df_salario_minimo.drop('obs_status.label', axis=1, inplace=True)\n",
    "df_salario_minimo.drop('note_indicator', axis=1, inplace=True)\n",
    "df_salario_minimo.drop('note_indicator.label', axis=1, inplace=True)\n",
    "df_salario_minimo.drop('note_source', axis=1, inplace=True)\n",
    "df_salario_minimo.drop('note_source.label', axis=1, inplace=True)\n",
    "df_salario_minimo.rename(columns={'ref_area':'codigo_pais', 'ref_area.label':'pais', 'time':'anio', 'obs_value':'salario_minimo'}, inplace=True)\n",
    "df_salario_minimo = df_salario_minimo[(df_salario_minimo['anio'] >= 1990)]\n",
    "\n",
    "#Cargamos nuestro dataset\n",
    "df_average_wages = wr.s3.read_csv(path='s3://data-fm-05/raw_data/average_wages.csv',sep=',', header=0, boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_average_wages.drop('INDICATOR', axis=1, inplace=True)\n",
    "df_average_wages.drop('SUBJECT', axis=1, inplace=True)\n",
    "df_average_wages.drop('MEASURE', axis=1, inplace=True)\n",
    "df_average_wages.drop('FREQUENCY', axis=1, inplace=True)\n",
    "df_average_wages.drop('Flag Codes', axis=1, inplace=True)\n",
    "df_average_wages.rename(columns={'LOCATION':'codigo_pais', 'TIME':'anio', 'Value':'salario_promedio'}, inplace=True)\n",
    "\n",
    "#Cargamos nuestro dataset\n",
    "df_wage_levels = wr.s3.read_csv(path='s3://data-fm-05/raw_data/wage_levels.csv', sep=',', header=0, boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_wage_levels.drop('INDICATOR', axis=1, inplace=True)\n",
    "df_wage_levels.drop('MEASURE', axis=1, inplace=True)\n",
    "df_wage_levels.drop('FREQUENCY', axis=1, inplace=True)\n",
    "df_wage_levels.drop('Flag Codes', axis=1, inplace=True)\n",
    "df_wage_levels = df_wage_levels[(df_wage_levels['TIME'] >= 1990)]\n",
    "df_wage_levels_low = df_wage_levels[df_wage_levels['SUBJECT'] == 'LPAY'].rename(columns={'Value':'ingresos_altos'}).drop(['SUBJECT'], axis=1)\n",
    "df_wage_levels_high = df_wage_levels[df_wage_levels['SUBJECT'] == 'HPAY'].rename(columns={'Value':'ingresos_bajos'}).drop(['SUBJECT'], axis=1)\n",
    "\n",
    "df_wage_levels_merged = pd.merge(df_wage_levels_high, df_wage_levels_low, on=['LOCATION','TIME'], how='outer')\n",
    "df_wage_levels_merged.rename(columns={'LOCATION':'codigo_pais', 'SUBJECT':'tipo', 'TIME': 'anio'}, inplace=True)\n",
    "\n",
    "#Cargamos nuestro dataset\n",
    "agricultura = wr.s3.read_csv(path='s3://data-fm-05/raw_data/empleos_agricultura.csv', boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "agricultura.drop(['Indicator Name','Indicator Code',\"1960\",\"1961\",\"1962\",\"1963\",\"1964\",\"1965\",\"1966\",\"1967\",\"1968\",\"1969\",\"1970\",\"1971\",\"1972\",\"1973\",\"1974\",\"1975\",\"1976\",\"1977\",\"1978\",\"1979\",\"1980\",\"1981\",\"1982\",\"1983\",\"1984\",\"1985\",\"1986\",\"1987\",\"1988\",\"1989\",'1990','2020','2021','Unnamed: 66'], axis=1, inplace= True)\n",
    "agricultura = agricultura.melt(id_vars=['Country Name','Country Code'], var_name='anio', value_name='%empleo_agricultura')\n",
    "agricultura.rename(columns={'Country Name':'pais','Country Code':'codigo_pais'}, inplace=True)\n",
    "agricultura['anio'] = agricultura['anio'].astype('int64')\n",
    "\n",
    "#Cargamos nuestro dataset\n",
    "industria = wr.s3.read_csv(path= 's3://data-fm-05/raw_data/empleos_industria.csv', boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "industria.drop(['Indicator Name','Indicator Code',\"1960\",\"1961\",\"1962\",\"1963\",\"1964\",\"1965\",\"1966\",\"1967\",\"1968\",\"1969\",\"1970\",\"1971\",\"1972\",\"1973\",\"1974\",\"1975\",\"1976\",\"1977\",\"1978\",\"1979\",\"1980\",\"1981\",\"1982\",\"1983\",\"1984\",\"1985\",\"1986\",\"1987\",\"1988\",\"1989\",'1990','2020','2021','Unnamed: 66'], axis=1, inplace= True)\n",
    "industria = industria.melt(id_vars=['Country Name','Country Code'], var_name='anio', value_name='%empleo_industria')\n",
    "industria.rename(columns={'Country Name':'pais','Country Code':'codigo_pais'}, inplace=True)\n",
    "industria['anio'] = industria['anio'].astype('int64')\n",
    "\n",
    "#Cargamos nuestro dataset\n",
    "servicio = wr.s3.read_csv(path='s3://data-fm-05/raw_data/empleos_servicio.csv', boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "servicio.drop(['Indicator Name','Indicator Code',\"1960\",\"1961\",\"1962\",\"1963\",\"1964\",\"1965\",\"1966\",\"1967\",\"1968\",\"1969\",\"1970\",\"1971\",\"1972\",\"1973\",\"1974\",\"1975\",\"1976\",\"1977\",\"1978\",\"1979\",\"1980\",\"1981\",\"1982\",\"1983\",\"1984\",\"1985\",\"1986\",\"1987\",\"1988\",\"1989\",'1990','2020','2021','Unnamed: 66'], axis=1, inplace= True)\n",
    "servicio = servicio.melt(id_vars=['Country Name','Country Code'], var_name='anio', value_name='%empleo_servicio')\n",
    "servicio.rename(columns={'Country Name':'pais','Country Code':'codigo_pais'}, inplace=True)\n",
    "servicio['anio'] = servicio['anio'].astype('int64')\n",
    "\n",
    "#Realizamos un merge de varios dataframes para crear uno completo\n",
    "merge1 = pd.merge(pib, df_salario_minimo, on=['codigo_pais','pais','anio'], how='outer')\n",
    "merge2 = pd.merge(merge1, df_average_wages, on=['codigo_pais','anio'], how='outer')\n",
    "merge3 = pd.merge(merge2, df_wage_levels_merged, on=['codigo_pais','anio'], how='outer')\n",
    "merge4 =pd.merge(merge3, agricultura, on=['codigo_pais','pais','anio'], how='outer')\n",
    "merge5 = pd.merge(merge4, industria, on=['codigo_pais','pais','anio'], how='outer')\n",
    "\n",
    "fact_ind_economico = pd.merge(merge5, servicio, on=['codigo_pais','pais','anio'], how='outer')\n",
    "\n",
    "\n",
    "#Enviamos el dataset limpio a otro bucket\n",
    "wr.s3.to_csv(df=fact_ind_economico, path=\"s3://data-fm-05/clean_data/fact_ind_economico.csv\", boto3_session=my_session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fact Ind Econonómico**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos nuestro dataset\n",
    "df_derechos_laborales = wr.s3.read_csv(path=\"s3://data-fm-05/raw_data/regulacion_juridica_al_empleo.csv\", sep=',', header=0, boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_derechos_laborales.drop('source', axis=1, inplace=True)\n",
    "df_derechos_laborales.drop('source.label', axis=1, inplace=True)\n",
    "df_derechos_laborales.drop('indicator', axis=1, inplace=True)\n",
    "df_derechos_laborales.drop('indicator.label',axis=1, inplace=True)\n",
    "df_derechos_laborales.rename(columns={'ref_area':'codigo_pais', 'ref_area.label':'pais','time':'anio','obs_value':'derechos_laborales'}, inplace=True)\n",
    "\n",
    "#Cargamos nuestro dataset\n",
    "df_human_rights = wr.s3.read_csv(path='s3://data-fm-05/raw_data/distribution-human-rights.csv', sep=',', header=0, boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_human_rights.rename(columns={'Entity':'pais', 'Code':'codigo_pais', 'Year':'anio', 'civ_libs_vdem_owid': 'derechos_humanos'}, inplace=True)\n",
    "df_human_rights.dropna(subset=['derechos_humanos'], inplace=True)\n",
    "df_human_rights.drop('codigo_pais', axis=1, inplace=True)\n",
    "df_human_rights = df_human_rights[(df_human_rights['anio'] >= 1990)]\n",
    "\n",
    "#Cargamos nuestro dataset\n",
    "df_gender_wage_gap = wr.s3.read_csv(path='s3://data-fm-05/raw_data/gender_wage_gap.csv', sep=',', header=0, boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_gender_wage_gap.drop('INDICATOR', axis=1, inplace=True)\n",
    "df_gender_wage_gap.drop('MEASURE', axis=1, inplace=True)\n",
    "df_gender_wage_gap.drop('FREQUENCY', axis=1, inplace=True)\n",
    "df_gender_wage_gap.drop('Flag Codes', axis=1, inplace=True)\n",
    "df_gender_wage_gap.rename(columns={'LOCATION':'codigo_pais', 'SUBJECT':'tipo', 'TIME':'anio', 'Value':'valor'}, inplace=True)\n",
    "df_gender_wage_gap = df_gender_wage_gap[(df_gender_wage_gap['anio'] >= 1990)]\n",
    "df_gender_wage_gap_employee = df_gender_wage_gap[df_gender_wage_gap['tipo'] == 'EMPLOYEE'].rename(columns={'valor':'brecha_salarial_empleo'}).drop(['tipo'], axis=1)\n",
    "df_gender_wage_gap_selfemployed = df_gender_wage_gap[df_gender_wage_gap['tipo'] == 'SELFEMPLOYED'].rename(columns={'valor':'brecha_salarial_autoempleo'}).drop(['tipo'], axis=1)\n",
    "df_gender_wage_gap_merged = pd.merge(df_gender_wage_gap_employee, df_gender_wage_gap_selfemployed, on=['codigo_pais','anio'], how='outer')\n",
    "\n",
    "#Cargamos nuestro dataset\n",
    "df_gini = wr.s3.read_csv(path='s3://data-fm-05/raw_data/gini.csv', boto3_session=my_session)\n",
    "\n",
    "#Hacemos transformaciones\n",
    "df_gini.rename(columns={'Code':'codigo_pais', 'Entity':'pais', 'Year':'anio', 'Gini coefficient':'coeficiente_gini'}, inplace=True)\n",
    "\n",
    "#Realizamos un merge de varios dataframes para crear uno completo\n",
    "merge1 = pd.merge(df_derechos_laborales, df_human_rights, on=['pais','anio'], how='outer')\n",
    "merge2 = pd.merge(merge1, df_gini, on=['codigo_pais','pais','anio'], how='outer')\n",
    "\n",
    "fact_ind_sociopolitico = pd.merge(merge2, df_gender_wage_gap_merged, on=['codigo_pais',\t'anio'], how='outer')\n",
    "\n",
    "\n",
    "#Enviamos el dataset limpio a otro bucket\n",
    "wr.s3.to_csv(df=fact_ind_sociopolitico, path=\"s3://data-fm-05/clean_data/fact_ind_sociopolitico.csv\", boto3_session=my_session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de Datos a Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establecemos conexión con la base de datos\n",
    "con = wr.redshift.connect(connection=\"connection\", boto3_session=my_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos el dataset limpio\n",
    "fact_empleo_condicion = wr.s3.read_csv(path=\"s3://data-fm-05/clean_data/fact_empleo_condicion.csv\", boto3_session=my_session)\n",
    "\n",
    "#Cargamos la tabla a la base de datos\n",
    "wr.redshift.copy(\n",
    "    df = fact_empleo_condicion,\n",
    "    path = \"s3://path\",\n",
    "    con=con,\n",
    "    table=\"fact_empleo_condicion\",\n",
    "    schema= \"public\",\n",
    "    iam_role= \"iam_role\",\n",
    "    boto3_session=my_session,\n",
    "    mode= \"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos el dataset limpio\n",
    "fact_ind_economico = wr.s3.read_csv(path=\"s3://data-fm-05/clean_data/fact_ind_economico.csv\", boto3_session=my_session)\n",
    "\n",
    "#Cargamos la tabla a la base de datos\n",
    "wr.redshift.copy(\n",
    "    df = fact_ind_economico,\n",
    "    path = \"s3://path\",\n",
    "    con=con,\n",
    "    table=\"fact_ind_economico\",\n",
    "    schema= \"public\",\n",
    "    iam_role= \"iam_role\",\n",
    "    boto3_session=my_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos el dataset limpio\n",
    "fact_ind_sociopolitico = wr.s3.read_csv(path=\"s3://data-fm-05/clean_data/fact_ind_sociopolitico.csv\", boto3_session=my_session)\n",
    "\n",
    "#Cargamos la tabla a la base de datos\n",
    "wr.redshift.copy(\n",
    "    df = fact_ind_sociopolitico,\n",
    "    path = \"s3://path\",\n",
    "    con=con,\n",
    "    table=\"fact_ind_sociopolitico\",\n",
    "    schema= \"public\",\n",
    "    iam_role= \"iam_role\",\n",
    "    boto3_session=my_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos el dataset limpio\n",
    "fact_migracion_industria = wr.s3.read_csv(path=\"s3://data-fm-05/clean_data/industry_migration_public.csv\", boto3_session=my_session)\n",
    "\n",
    "#Cargamos la tabla a la base de datos\n",
    "wr.redshift.copy(\n",
    "    df = fact_migracion_industria,\n",
    "    path = \"s3://path\",\n",
    "    con=con,\n",
    "    table=\"fact_ind_sociopolitico\",\n",
    "    schema= \"public\",\n",
    "    iam_role= \"iam_role\",\n",
    "    boto3_session=my_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos el dataset limpio\n",
    "fact_migracion_skills = wr.s3.read_csv(path=\"s3://data-fm-05/clean_data/skill_migration_public.csv\", boto3_session=my_session)\n",
    "\n",
    "#Cargamos la tabla a la base de datos\n",
    "wr.redshift.copy(\n",
    "    df = fact_migracion_skills,\n",
    "    path = \"s3://path\",\n",
    "    con=con,\n",
    "    table=\"fact_ind_sociopolitico\",\n",
    "    schema= \"public\",\n",
    "    iam_role= \"iam_role\",\n",
    "    boto3_session=my_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos el dataset limpio\n",
    "dim_pais = wr.s3.read_csv(path=\"s3://data-fm-05/clean_data/dim_pais.csv\", boto3_session=my_session)\n",
    "\n",
    "#Cargamos la tabla a la base de datos\n",
    "wr.redshift.copy(\n",
    "    df = dim_pais,\n",
    "    path = \"s3://path\",\n",
    "    con=con,\n",
    "    table=\"fact_ind_sociopolitico\",\n",
    "    schema= \"public\",\n",
    "    iam_role= \"iam_role\",\n",
    "    boto3_session=my_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_calendario = wr.s3.read_csv(path=\"s3://data-fm-05/clean_data/dim_calendario.csv\", boto3_session=my_session)\n",
    "\n",
    "#Cargamos la tabla a la base de datos\n",
    "wr.redshift.copy(\n",
    "    df = dim_calendario,\n",
    "    path = \"s3://path\",\n",
    "    con=con,\n",
    "    table=\"fact_ind_sociopolitico\",\n",
    "    schema= \"public\",\n",
    "    iam_role= \"iam_role\",\n",
    "    boto3_session=my_session\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizamos la conexión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42153c4c753c9b011111c714d0476e53a03e7d305dd65353e4e91ed368c332d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
